{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b4d05b",
   "metadata": {},
   "source": [
    "# [KIRIN-728](https://jira.ssc.lmco.com:7443/browse/KIRIN-728): Distribution Plotting of Features\n",
    "\n",
    "---\n",
    "\n",
    "Create distribution plots of features. Based on results from ~~[KIRIN-716](https://jira.ssc.lmco.com:7443/browse/KIRIN-716)~~, there seems to be some files that probably have some odd behaviors in their features. Also might want to split between CoA vs no CoA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecd5b8",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8800dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "data_directory = glob.glob(\"/domino/datasets/unified-hdf-feature-data/*.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aea393",
   "metadata": {},
   "source": [
    "## Organize data\n",
    "from \"/unified-hdf-feature-data\" directory, create 4 batchs of 1000 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e4bea4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Files Loaded:\n",
      "5000 10000 "
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "#Change these.................................................\n",
    "batch_size = 5000 # 1000 takes too long and domino sucks and breaks\n",
    "file_limit = 10000\n",
    "\n",
    "print(\"Number of Files Loaded:\")\n",
    "batch_number = 1 # ex. batch1\n",
    "start = 0\n",
    "current_position = batch_size\n",
    "batchs = []\n",
    "for batch in data_directory:\n",
    "    globals()[f\"batch{batch_number}\"] = [] # ex. batch1[]\n",
    "    \n",
    "    if current_position > file_limit:\n",
    "        break\n",
    "    \n",
    "    # add files to batch\n",
    "    [globals()[f\"batch{batch_number}\"].append(file) for file in data_directory[start:current_position]] # ex. batch1[0:1000]\n",
    "\n",
    "    # add batchs to list\n",
    "    batchs.append(globals()[f\"batch{batch_number}\"])# ex. batchs[batch1, batch2]\n",
    "    \n",
    "    batch_number+=1\n",
    "    start+=batch_size\n",
    "    print(current_position, end=\" \")\n",
    "    current_position+=batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca9741",
   "metadata": {},
   "source": [
    "## Clean/Prepare Data\n",
    "1. Combine files in batchs[batch1] into 1 DF\n",
    "2. Add \"File\" column for the range \n",
    "3. Add all DFs to a list for plotting\n",
    "4. Combine into single DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batchs Loaded:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Batchs Loaded:\")\n",
    "start = 0\n",
    "all_batchs = []\n",
    "for batch in batchs:\n",
    "     # combine files in batchs[batch1] into 1 DF\n",
    "    df = pd.concat((map(pd.read_hdf, batch)))\n",
    "    \n",
    "    # add \"File\" column for the range \n",
    "    df.insert(0, \"Files\", f\"{start}-{start + batch_size}\", True ) # ex. [Files][0-1000]\n",
    "    start+=batch_size\n",
    "    \n",
    "    # add all DFs to a list for plotting\n",
    "    all_batchs.append(df)\n",
    "    \n",
    "    print(f\"{start - batch_size}-{start}\", end=\" \") # reverse because batch_size has been incremented\n",
    "    \n",
    "# combine into single DF\n",
    "df = pd.concat(all_batchs)\n",
    "df = pd.DataFrame(df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab376185",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Plot Settings\n",
    "plt.rcParams[\"figure.figsize\"]=12,8\n",
    "sns.set(style=\"whitegrid\")\n",
    "path=\"/mnt/kirin_ml/unified_nn_training/feature_plot_graphs\"\n",
    "\n",
    "print(\"Features loaded:\")\n",
    "columns = list(df)\n",
    "for column in columns[1:-1]: # exclude [Files] & [coa]\n",
    "    sns.kdeplot(data=df, x=column, hue=\"Files\", bw_adjust=.9, cut=0, palette=\"tab10\", linewidth=3, fill=True, alpha=.1, legend=True)\n",
    "    \n",
    "    # save plot\n",
    "    name = f'{column}.png'\n",
    "    destination = os.path.join(path, name)\n",
    "    plt.savefig(destination)\n",
    "        \n",
    "    print(f\"{column} \", end=\"\")\n",
    "#     plt.show(block=False) # display inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5ca45",
   "metadata": {},
   "source": [
    "### TODO: Make seperate DF and distribution plots for no-COA(coa=0)\n",
    "- Remove coa=0 rows from column then rerun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Files with Unique COAs\n",
    "# [print(file, pd.read_hdf(file)[\"coa\"].unique()) for file in files[0:11]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}